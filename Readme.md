# Llama 3

According to Meta, the release of Llama 3 features pretrained and instruction fine-tuned language models with 8B and 70B parameter counts that can support a broad range of use cases including summarization, classification, information extraction, and content grounded question and answering. The 8B model is designed for faster training and edge devices, while the 70B model is designed for content creation, conversational AI, language understanding, research and development and enterprise applications. Meta has stated Llama 3 is demonstrating improved performance when compared to Llama 2 based on Metaâ€™s internal testing. In the coming months, Meta expects to introduce new capabilities, additional model sizes, and enhanced performance, and the Llama 3 research paper.

## Accessing Llama-3

To access Llama-3, follow these steps:

1. Go to this link [Meta-Llama-3-8B](https://huggingface.co/meta-llama/Meta-Llama-3-8B).
2. Apply for Llama-3 access.
3. Once approved, you will receive an email in your inbox.
4. Create a HuggingFace access token.
5. Define your token as `YOUR_HuggingFACE_API_KEY`.

### Load And Initialize Meta-Llama-3-8B-Instruct Model

### Modify the input prompt according to your desire if Needed

### Generate Text Using Llama-3 Through Streaming

#### THe GPU Used is V100 on Google Colab
